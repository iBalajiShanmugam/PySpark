{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ae38468",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/02/16 05:36:28 WARN Utils: Your hostname, LAPTOP-DHIBVMKK resolves to a loopback address: 127.0.1.1; using 172.27.190.130 instead (on interface eth0)\n",
      "23/02/16 05:36:28 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/02/16 05:36:30 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "%run sparkCreate.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daba959c",
   "metadata": {},
   "source": [
    "# Creating Spark DataFrame using Python Collection object "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a0547def",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+\n",
      "|value|\n",
      "+-----+\n",
      "|   12|\n",
      "|   23|\n",
      "|   44|\n",
      "|    2|\n",
      "+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#create single column DataFrme wtih Integer list\n",
    "ages_list = [12,23,44,2]\n",
    "\n",
    "df = spark.createDataFrame(ages_list, 'int')\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5528214a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+\n",
      "|value|\n",
      "+-----+\n",
      "|   12|\n",
      "|   23|\n",
      "|   44|\n",
      "|    2|\n",
      "+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from pyspark.sql.types import IntegerType\n",
    "df = spark.createDataFrame(ages_list, IntegerType())\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6195f641",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n",
      "| value|\n",
      "+------+\n",
      "|python|\n",
      "|  java|\n",
      "|   SQL|\n",
      "+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#create single column DataFrme wtih String list\n",
    "\n",
    "from pyspark.sql.types import StringType\n",
    "names_list =[\"python\", \"java\",\"SQL\"]\n",
    "spark.createDataFrame(names_list, StringType()).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "10673753",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+\n",
      "| id|\n",
      "+---+\n",
      "| 12|\n",
      "| 23|\n",
      "+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#create multiple column DataFrme wtih list of tuple  \n",
    "\n",
    "ages_list = [(12,),(23,)]\n",
    "spark.createDataFrame(ages_list,'id int').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2f6797f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+\n",
      "| id|Name|\n",
      "+---+----+\n",
      "| 12|elon|\n",
      "| 23|john|\n",
      "| 99| bob|\n",
      "+---+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "users_list = [(12,'elon'), (23,'john'), (99, 'bob')]\n",
    "spark.createDataFrame(users_list, ['id','Name']).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f36242a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(id=12, Name='elon'), Row(id=23, Name='john'), Row(id=99, Name='bob')]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.createDataFrame(users_list, ['id','Name']).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6e2eb935",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Row(12, 'apple')>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import Row\n",
    "row = Row(12,'apple')\n",
    "\n",
    "row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fee3da41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+\n",
      "| id|name|\n",
      "+---+----+\n",
      "|  1| bob|\n",
      "|  2|john|\n",
      "|  3|bala|\n",
      "+---+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#create multiple column DataFrme wtih list of list\n",
    "\n",
    "list_users = [[1,'bob'],[2, 'john'], [3, 'bala']]\n",
    "df = spark.createDataFrame(list_users, 'id int, name string').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "260fc76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create multiple column DataFrme wtih list of Dict\n",
    "#this approch deprecated \n",
    "\n",
    "user_dict = [\n",
    "    {'id':1, 'name':\"john\"},\n",
    "    {'id':2, 'name':\"kevin\"}  \n",
    "]\n",
    "\n",
    "df = spark.createDataFrame(user_dict).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b47e06b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+\n",
      "| id| name|\n",
      "+---+-----+\n",
      "|  1| john|\n",
      "|  2|kevin|\n",
      "+---+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import Row\n",
    "\n",
    "user_dict = [\n",
    "    {'id':1, 'name':\"john\"},\n",
    "    {'id':2, 'name':\"kevin\"}  \n",
    "]\n",
    "\n",
    "user_row = [Row(*user) for user in user_dict]\n",
    "\n",
    "df = spark.createDataFrame(user_dict, 'id int, name string').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "a9115321",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spark Basic Data Types\n",
    "\n",
    "import datetime\n",
    "users = [   \n",
    "    {\n",
    "        \"id\": 1,\n",
    "        \"first_name\": \"Corrie\",\n",
    "        \"last_name\": \"Van den Oord\",\n",
    "        \"email\": \"cvandenoor0@etsy.com\",\n",
    "        \"is_customer\": True,\n",
    "        \"amount_paid\": 1000.55,\n",
    "        \"customer_from\": datetime.date(2021, 1, 15),\n",
    "        \"last_updated_ts\": datetime.datetime(2021, 2, 10, 1, 15, 0)\n",
    "    },\n",
    "    {\n",
    "        \"id\": 2,\n",
    "        \"first_name\": \"John\",\n",
    "        \"last_name\": \"Doe\",\n",
    "        \"email\": \"jdoe@example.com\",\n",
    "        \"is_customer\": True,\n",
    "        \"amount_paid\": 500.00,\n",
    "        \"customer_from\": datetime.date(2021, 4, 2),\n",
    "        \"last_updated_ts\": datetime.datetime(2022, 10, 15, 12, 30, 0)\n",
    "    },\n",
    "    {\n",
    "        \"id\": 3,\n",
    "        \"first_name\": \"Jane\",\n",
    "        \"last_name\": \"Doe\",\n",
    "        \"email\": \"janedoe@example.com\",\n",
    "        \"is_customer\": True,\n",
    "        \"amount_paid\": 250.99,\n",
    "        \"customer_from\": datetime.date(2020, 12, 31),\n",
    "        \"last_updated_ts\": datetime.datetime(2022, 8, 20, 9, 0, 0)\n",
    "    },\n",
    "    {\n",
    "        \"id\": 4,\n",
    "        \"first_name\": \"Bob\",\n",
    "        \"last_name\": \"Smith\",\n",
    "        \"email\": \"bsmith@example.com\",\n",
    "        \"is_customer\": False,\n",
    "        \"amount_paid\": None,\n",
    "        \"customer_from\": None,\n",
    "        \"last_updated_ts\": datetime.datetime(2022, 1, 1, 15, 30, 0)\n",
    "    },\n",
    "    {\n",
    "        \"id\": 5,\n",
    "        \"first_name\": \"Emily\",\n",
    "        \"last_name\": \"Jones\",\n",
    "        \"email\": \"ejones@example.com\",\n",
    "        \"is_customer\": True,\n",
    "        \"amount_paid\": 750.50,\n",
    "        \"customer_from\": datetime.date(2021, 6, 15),\n",
    "        \"last_updated_ts\": datetime.datetime(2022, 12, 5, 17, 45, 0)\n",
    "    },\n",
    "    {\n",
    "        \"id\": 6,\n",
    "        \"first_name\": \"Mark\",\n",
    "        \"last_name\": \"Johnson\",\n",
    "        \"email\": \"mjohnson@example.com\",\n",
    "        \"is_customer\": True,\n",
    "        \"amount_paid\": 1500.00,\n",
    "        \"customer_from\": datetime.date(2020, 5, 10),\n",
    "        \"last_updated_ts\": datetime.datetime(2023, 1, 10, 8, 0, 0)\n",
    "    },\n",
    "    {\n",
    "        \"id\": 7,\n",
    "        \"first_name\": \"Samantha\",\n",
    "        \"last_name\": \"Lee\",\n",
    "        \"email\": \"slee@example.com\",\n",
    "        \"is_customer\": False,\n",
    "        \"amount_paid\": None,\n",
    "        \"customer_from\": None,\n",
    "        \"last_updated_ts\": datetime.datetime(2022, 9, 1, 10, 0, 0)\n",
    "    },\n",
    "    {\n",
    "        \"id\": 8,\n",
    "        \"first_name\": \"Michael\",\n",
    "        \"last_name\": \"Brown\",\n",
    "        \"email\": \"mbrown@example.com\",\n",
    "        \"is_customer\": True,\n",
    "        \"amount_paid\": 350.75,\n",
    "        \"customer_from\": datetime.date(2022, 1, 20),\n",
    "        \"last_updated_ts\": datetime.datetime(2022, 11, 30, 14, 15, 0)\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "b889ece2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: long (nullable = true)\n",
      " |-- first_name: string (nullable = true)\n",
      " |-- last_name: string (nullable = true)\n",
      " |-- email: string (nullable = true)\n",
      " |-- is_customer: boolean (nullable = true)\n",
      " |-- amount_paid: double (nullable = true)\n",
      " |-- customer_from: date (nullable = true)\n",
      " |-- last_updated_ts: timestamp (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import Row\n",
    "\n",
    "user_df = spark.createDataFrame([Row(**user) for user in users])\n",
    "user_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "45b524e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+------------+--------------------+-----------+-----------+-------------+-------------------+\n",
      "| id|first_name|   last_name|               email|is_customer|amount_paid|customer_from|    last_updated_ts|\n",
      "+---+----------+------------+--------------------+-----------+-----------+-------------+-------------------+\n",
      "|  1|    Corrie|Van den Oord|cvandenoor0@etsy.com|       true|    1000.55|   2021-01-15|2021-02-10 01:15:00|\n",
      "|  2|      John|         Doe|    jdoe@example.com|       true|      500.0|   2021-04-02|2022-10-15 12:30:00|\n",
      "|  3|      Jane|         Doe| janedoe@example.com|       true|     250.99|   2020-12-31|2022-08-20 09:00:00|\n",
      "|  4|       Bob|       Smith|  bsmith@example.com|      false|       null|         null|2022-01-01 15:30:00|\n",
      "|  5|     Emily|       Jones|  ejones@example.com|       true|      750.5|   2021-06-15|2022-12-05 17:45:00|\n",
      "|  6|      Mark|     Johnson|mjohnson@example.com|       true|     1500.0|   2020-05-10|2023-01-10 08:00:00|\n",
      "|  7|  Samantha|         Lee|    slee@example.com|      false|       null|         null|2022-09-01 10:00:00|\n",
      "|  8|   Michael|       Brown|  mbrown@example.com|       true|     350.75|   2022-01-20|2022-11-30 14:15:00|\n",
      "+---+----------+------------+--------------------+-----------+-----------+-------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "user_df.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0144114e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
